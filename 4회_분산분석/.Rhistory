Data <- read.csv('C:/Users/ksn71/OneDrive/바탕 화면/2.Iris (1).csv')
colnames(Data)
sd(Data$Petal.Width)
sd(Data$Petal.Width)
Data <- read.csv('C:/Users/ksn71/OneDrive/바탕 화면/2.Iris (1).csv')
# 열 이름 보
colnames(Data)
#평균 구하기 각 열의
mean(Data$Sepal.Length)
mean(Data$Sepal.Width)
mean(Data$Petal.Length)
mean(Data$Petal.Width)
#분산 구하기 각 열의
var(Data$Sepal.Length)
var(Data$Sepal.Width)
var(Data$Petal.Length)
var(Data$Petal.Width)
# 표준편차 구하기 각 열
sd(Data$Sepal.Length)
sd(Data$Sepal.Width)
sd(Data$Petal.Length)
sd(Data$Petal.Width)
# 각 변수의 표준화
Data_standardized <- scale(Data)
Data <- read.csv('C:/Users/ksn71/OneDrive/바탕 화면/2.Iris (1).csv', fileEncoding = "UTF-8")
# 각 변수의 표준화
Data_standardized <- scale(Data)
#표준평균
mean(Data$Sepal.Length)
mean(Data$Sepal.Width)
mean(Data$Petal.Length)
mean(Data$Petal.Width)
#표준분산
var(Data$Sepal.Length)
var(Data$Sepal.Width)
var(Data$Petal.Length)
var(Data$Petal.Width)
#표준평균
mean(Data_standardized$Sepal.Length)
mean(Data_standardized$Sepal.Width)
mean(Data_standardized$Petal.Length)
mean(Data_standardized$Petal.Width)
#표준분산
var(Data_standardized$Sepal.Length)
var(Data_standardized$Sepal.Width)
var(Data_standardized$Petal.Length)
var(Data_standardized$Petal.Width)
# 각 변수의 표준화
Data_standardized <- scale(Data)
View(Data_standardized)
View(Data)
# 각 변수의 표준화
Data_standardized <- as.data.frame(scale(Data))
#표준평균
mean(Data_standardized$Sepal.Length)
mean(Data_standardized$Sepal.Width)
mean(Data_standardized$Petal.Length)
mean(Data_standardized$Petal.Width)
#표준분산
var(Data_standardized$Sepal.Length)
var(Data_standardized$Sepal.Width)
var(Data_standardized$Petal.Length)
var(Data_standardized$Petal.Width)
# 피어슨 상관계수 계산
correlation_matrix <- cor(Data_standardized, method = "pearson")
# 결과 출력
correlation_matrix
options(width=100)
longley
str(longley)
pairs(longley, main = "자료?? : longley")
pairs(longley, main = "자료명 : longley")
pairs(longley, main = "자료명 : longley")
Cl <- cor(longley)
Cl
symnum(Cl) # highly correlated
i <- lower.tri(Cl)
cor(cbind(P = Cl[i], S = clS[i], K = clK[i]))
symnum(clS <- cor(longley, method = "spearman"))
cor(cbind(P = Cl[i], S = clS[i], K = clK[i]))
symnum(clK <- cor(longley, method = "kendall"))
cor(cbind(P = Cl[i], S = clS[i], K = clK[i]))
# 패키지 "corrgram"?냐?
library(corrgram)
corrgram(cor(longley), main = "상관계수의 시각화", type="corr",cor.method = "pearson", upper.panel=panel.conf)
# 패키지 "corrgram"?냐?
library(corrgram)
# 패키지 "corrgram"?냐?
install.packages("corrgram")
library(corrgram)
corrgram(cor(longley), main = "상관계수의 시각화", type="corr",cor.method = "pearson", upper.panel=panel.conf)
options(encoding = "UTF-8")
version
source("file:///C:/code_statistics/Report_Does Television.R", encoding = "EUC-KR")
R.version
######################
#모분산의 추정 및 검정
install.packages("TeachingDemos")
library(TeachingDemos)
x <- rnorm(20, mean = 15, sd = 7)
x
sigma.test(x, sigma = 6)
sigma.test(x, sigmasq = 36)
sigma.test(x, sigma = 6, alternative = "greater")
X=c(1:10)
X
y=c(7:20)
y
t.test(x, y )
t.test(x,y, var.equal=TRUE)
##################################
#모분산의 차이에 대한 추정 및 검정
x <- rnorm(25, mean = 15, sd = 9)
y <- rnorm(20, mean = 10, sd = 7)
length(x);  mean(x);  var(x)
length(y);  mean(y);  var(y)
var.test(x, y)          # Do x and y have the same variance?
var.test(x, y, alternative = c("greater"))
#회귀분석
#단순선형회귀분석
# 나이와 최대 심장 박동수와의 관계
# Max = 220 - Age
Age <- c(18,23,25,35,65,54,34,56,72,19,23,42,18,39,37)
Max <- c(202,186,187,180,156,169,174,172,153,199,193,174,198,183,178)
Data = data.frame( Age, Max )
Ma <- lm(Max ~ Age, Data)
Ma
names(Ma)
plot( Age, Max, main = "자료와 회귀직선" )
abline(coef(Ma))
summary(Ma)
anova(Ma)
deviance(Ma)       # 또는
sum( ( Max - predict(Ma))^2)
str(Ma)
str(summary(Ma))
str(anova(Ma))
anova(Ma)$Df
anova(Ma)$Sum
anova(Ma)$Mean
anova(Ma)$F
anova(Ma)$Pr
confint(Ma)        # 또는 confint(Ma, level = 0.95)
fitted.values(Ma)  # 또는 fitted(Ma)
residuals(Ma)
predict(Ma)
predict(Ma, interval="confidence",level = 0.95)
predict(Ma, interval="prediction",level = 0.95)
predict(Ma, data.frame(Age=20))
predict(Ma, data.frame(Age=20), interval="confidence")
predict(Ma, data.frame(Age=20), interval="prediction")
opar <- par(mfrow = c(2,3))
plot(Ma, which=c(1:6), las = 1)
par(opar)
Age <- seq(min(Age), max(Age),0.1)
Pc <- predict(Ma, data.frame(Age), interval="confidence")
Pp <- predict(Ma, data.frame(Age), interval="prediction")
matplot(Age, Pc, main="예측값의 신뢰구간", ylab="Max", type='l', lty=1, col="black")
matlines(Age, Pp, type='l', lty=2,col=c("black", "red", "red"))
rep(1:4, c(1,1,1,1))
setwd("C:/Users/ksn71/OneDrive/바탕 화면/git/statistics/4회_분산분석")
rep(1:4, c(1,1,1,1))
rep(rep(1:4, c(1,1,1,1)),3)
factor(rep(rep(1:4, c(1,1,1,1)),3))
region = factor(rep(rep(1:4, c(1,1,1,1)),3))
region
fertile = factor(rep(1:3, c(4,4,4)))
factor(rep(1:3, c(4,4,4)))
product = c(42.8, 38.6, 50.2, 48.2, 52.3, 43.5,
58.7, 50.8, 48.2, 40.3, 53.5, 51.2 )
region = factor(rep(rep(1:4, c(1,1,1,1)),3))
fertile = factor(rep(1:3, c(4,4,4)))
anova(lm(product ~ region + fertile))
aov(product  ~ region + fertile)
summary(aov( sell ~ size * design ))
aov(product  ~ region + fertile)
summary(aov(product  ~ region + fertile))
# 반복측정이 있는 경우
sell = c( 23, 20, 21, 22, 19, 20, 19, 18, 21,
22, 20, 19, 20, 21, 22, 20, 19, 22,
18, 18, 16, 21, 23, 20, 20, 22, 24)
design = factor( rep( rep(1:3, c(3,3,3)), 3))
size = factor( rep( 1:3, c(9,9,9)))
anova( lm ( sell ~ size * design ))
summary(aov( sell ~ size * design ))
attach(mtcars);  Gear <- factor(gear);  Cyl <- factor(cyl)
opar <- par(mfrow = c(1,2))
interaction.plot(Cyl, Gear, mpg, type="b", col=c(1:3),
leg.bty="o", leg.bg="beige", lwd=2, pch=c(18,24,22),
xlab="Number of Cylinders",
ylab="Mean Miles Per Gallon",
main="Interaction Plot 1")
interaction.plot(Gear, Cyl, mpg, type="b", col=c(1:3),
leg.bty="o", leg.bg="beige", lwd=2, pch=c(18,24,22),
xlab="Number of Gears",
ylab="Mean Miles Per Gallon",
main="Interaction Plot 2")
par(opar)
table(gear, cyl)
# Randomized Block Design (B is the blocking factor)
summary(aov(mpg ~ Cyl + Gear, data=mtcars))
# Randomized Block Design (B is the blocking factor)
summary(aov(mpg ~ Cyl*Gear, data=mtcars))
# Plot Means with Error Bars
#install.packages("gplots")
library(gplots)
# Plot Means with Error Bars
install.packages("gplots")
# Plot Means with Error Bars
#install.packages("gplots")
library(gplots)
attach(mtcars)
Cyl <- factor(cyl)
library(gplots)
attach(mtcars)
Cyl <- factor(cyl)
plotmeans(mpg~Cyl,xlab="Number of Cylinders",
ylab="Miles Per Gallon", main="Mean Plot with 95% CI")
# Homogeneity of Variances
# Bartlett Test of Homogeneity of Variances
bartlett.test( mpg ~ Cyl, data=mtcars)
# Figner-Killeen Test of Homogeneity of Variances
fligner.test( mpg ~ Cyl, data=mtcars)
#install.packages("HH")
library(HH)
hov(mpg ~ Cyl, data=mtcars)
hovPlot(mpg ~ Cyl, data=mtcars)
# Homogeneity of Variance Plot
install.packages("HH")
hov(mpg ~ Cyl, data=mtcars)
hovPlot(mpg ~ Cyl, data=mtcars)
library(HH)
hov(mpg ~ Cyl, data=mtcars)
hovPlot(mpg ~ Cyl, data=mtcars)
# Homogeneity of Variances
# Bartlett Test of Homogeneity of Variances
bartlett.test( mpg ~ Cyl, data=mtcars)
# Figner-Killeen Test of Homogeneity of Variances
fligner.test( mpg ~ Cyl, data=mtcars)
# Homogeneity of Variance Plot
install.packages("HH")
library(HH)
hov(mpg ~ Cyl, data=mtcars)
hovPlot(mpg ~ Cyl, data=mtcars)
hov(mpg ~ Cyl, data=mtcars)
setwd("C:/Users/ksn71/OneDrive/바탕 화면/git/statistics/4회_분산분석")
hov(mpg ~ Cyl, data=mtcars)
library(HH)
hov(mpg ~ Cyl, data=mtcars)
# Homogeneity of Variance Plot
install.packages("HH")
